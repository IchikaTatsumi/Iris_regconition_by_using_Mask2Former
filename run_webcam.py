import cv2
import torch
import numpy as np
import json
import time
import albumentations as A
from albumentations.pytorch import ToTensorV2
import sys
import os

# ƒê·∫£m b·∫£o Python nh√¨n th·∫•y th∆∞ m·ª•c src
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

# Import model class (S·ª≠a l·∫°i ƒë∆∞·ªùng d·∫´n import n·∫øu c·∫•u tr√∫c th∆∞ m·ª•c c·ªßa b·∫°n kh√°c)
try:
    from src.models.mask2former import EnhancedMask2Former
except ImportError:
    print("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y module 'src'. H√£y ƒë·∫£m b·∫£o file n√†y n·∫±m ngang h√†ng v·ªõi th∆∞ m·ª•c 'src'.")
    sys.exit(1)

class IrisSegmentor:
    def __init__(self, config_path, checkpoint_path):
        # Ki·ªÉm tra CUDA
        if torch.cuda.is_available():
            self.device = torch.device('cuda')
            self.device_name = torch.cuda.get_device_name(0)
            print(f"üöÄ Hardware: {self.device_name} (Ready for RTX 3050 Optimization)")
        else:
            self.device = torch.device('cpu')
            print("‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y GPU. T·ªëc ƒë·ªô s·∫Ω r·∫•t ch·∫≠m!")

        # 1. Load Config
        print(f"üìñ Loading config: {config_path}")
        with open(config_path, 'r') as f:
            self.config = json.load(f)

        # 2. Chu·∫©n b·ªã config cho model (Lo·∫°i b·ªè c√°c key th·ª´a g√¢y l·ªói)
        model_cfg = self.config['model_config']
        
        # X√≥a key 'use_checkpoint' n·∫øu t·ªìn t·∫°i (nguy√™n nh√¢n g√¢y l·ªói tr∆∞·ªõc ƒë√≥)
        keys_to_remove = ['use_checkpoint']
        for key in keys_to_remove:
            if key in model_cfg:
                print(f"üîß Removing incompatible key: {key}")
                del model_cfg[key]
        
        # 3. Kh·ªüi t·∫°o Model
        print("üèóÔ∏è Initializing Model...")
        self.model = EnhancedMask2Former(**model_cfg)
        
        # 4. Load Weights (Tr·ªçng s·ªë)
        print(f"‚öñÔ∏è Loading checkpoint: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        if 'state_dict' in checkpoint:
            self.model.load_state_dict(checkpoint['state_dict'])
        else:
            self.model.load_state_dict(checkpoint)
            
        self.model.to(self.device)
        self.model.eval() # B·∫Øt bu·ªôc: Ch·∫ø ƒë·ªô Evaluation

        # 5. C·∫•u h√¨nh Transform (T·ªêI ∆ØU H√ìA CHO RTX 3050)
        # 384x384 l√† ƒëi·ªÉm c√¢n b·∫±ng t·ªët nh·∫•t gi·ªØa t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c cho GPU 4GB
        self.img_size = 384 
        print(f"‚öôÔ∏è Input Resolution set to: {self.img_size}x{self.img_size}")

        self.transform = A.Compose([
            A.Resize(height=self.img_size, width=self.img_size),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2()
        ])
        
        # B·∫£ng m√†u: Class 0 (Trong su·ªët), Class 1 (Xanh l√° - Iris)
        self.colors = np.array([
            [0, 0, 0],       # Background
            [0, 255, 0]      # Iris
        ], dtype=np.uint8)

    def predict(self, frame):
        """
        D·ª± ƒëo√°n Mask t·ª´ frame ·∫£nh (Webcam)
        """
        original_h, original_w = frame.shape[:2]

        # 1. Preprocess: Resize & Normalize
        # Chuy·ªÉn BGR (OpenCV) -> RGB (Model)
        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        augmented = self.transform(image=image_rgb)
        x_tensor = augmented['image'].unsqueeze(0).to(self.device) # Shape: [1, 3, 384, 384]

        # 2. Inference (QUAN TR·ªåNG: D√πng FP16 ƒë·ªÉ tƒÉng t·ªëc)
        with torch.no_grad():
            # T·ª± ƒë·ªông d√πng Mixed Precision (FP16) cho RTX 3050
            with torch.amp.autocast('cuda'): 
                outputs = self.model(x_tensor)
                
                # X·ª≠ l√Ω output (t√πy v√†o output c·ªßa model l√† dict hay tensor)
                if isinstance(outputs, dict):
                     logits = outputs['pred_masks'] # Key ph·ªï bi·∫øn c·ªßa Mask2Former
                else:
                     logits = outputs

                # L·∫•y class c√≥ x√°c su·∫•t cao nh·∫•t ngay tr√™n GPU
                # [1, 2, H, W] -> [H, W]
                pred_mask = torch.argmax(logits, dim=1).squeeze(0)

        # 3. Post-process
        # Chuy·ªÉn v·ªÅ CPU -> Numpy
        pred_mask_np = pred_mask.cpu().numpy().astype(np.uint8)
        
        # Resize mask v·ªÅ k√≠ch th∆∞·ªõc g·ªëc c·ªßa Webcam (d√πng Nearest ƒë·ªÉ gi·ªØ c·∫°nh s·∫Øc n√©t)
        pred_mask_resized = cv2.resize(pred_mask_np, (original_w, original_h), interpolation=cv2.INTER_NEAREST)
        
        return pred_mask_resized

    def draw_overlay(self, frame, mask, alpha=0.4):
        """
        V·∫Ω mask ch·ªìng l√™n ·∫£nh g·ªëc
        """
        # T·∫°o ·∫£nh m√†u t·ª´ mask index
        # mask c√≥ gi√° tr·ªã 0 ho·∫∑c 1. self.colors[mask] s·∫Ω map ra m√†u t∆∞∆°ng ·ª©ng
        color_mask = self.colors[mask]
        
        # Ch·ªâ blend m√†u t·∫°i v·ªã tr√≠ m·ªëng m·∫Øt (mask == 1)
        iris_pixels = mask == 1
        
        overlay = frame.copy()
        # C√¥ng th·ª©c blend: img * (1-alpha) + mask * alpha
        overlay[iris_pixels] = cv2.addWeighted(
            frame[iris_pixels], 1-alpha, 
            color_mask[iris_pixels], alpha, 
            0
        )
        return overlay

# --- CH∆Ø∆†NG TR√åNH CH√çNH ---
def main():
    # --- C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N (S·ª≠a l·∫°i n·∫øu t√™n file kh√°c) ---
    CONFIG_PATH = 'configs/mask2former_config_kaggle.json'
    CHECKPOINT_PATH = 'checkpoints/best_checkpoint.pth' # Ho·∫∑c 'training_results/...'

    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(CONFIG_PATH) or not os.path.exists(CHECKPOINT_PATH):
        print("‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y file Config ho·∫∑c Checkpoint!")
        print(f"   - Config: {CONFIG_PATH}")
        print(f"   - Checkpoint: {CHECKPOINT_PATH}")
        return

    # 1. Kh·ªüi t·∫°o Model
    try:
        segmentor = IrisSegmentor(CONFIG_PATH, CHECKPOINT_PATH)
        print("‚úÖ Model loaded successfully!")
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        import traceback
        traceback.print_exc()
        return

    # 2. M·ªü Webcam
    print("üé• Opening Webcam...")
    cap = cv2.VideoCapture(0)
    
    # Thi·∫øt l·∫≠p ƒë·ªô ph√¢n gi·∫£i Webcam (640x480 l√† chu·∫©n nh·∫π nh·∫•t ƒë·ªÉ hi·ªÉn th·ªã)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    if not cap.isOpened():
        print("‚ùå Kh√¥ng th·ªÉ m·ªü Webcam.")
        return

    print("\n" + "="*40)
    print("   NH·∫§N 'Q' ƒê·ªÇ THO√ÅT CH∆Ø∆†NG TR√åNH   ")
    print("="*40 + "\n")

    prev_time = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Cannot read frame.")
            break

        # Flip g∆∞∆°ng ƒë·ªÉ nh√¨n t·ª± nhi√™n h∆°n
        frame = cv2.flip(frame, 1)

        # ƒêo FPS
        current_time = time.time()
        
        # --- CH·∫†Y D·ª∞ ƒêO√ÅN ---
        mask = segmentor.predict(frame)
        
        # --- V·∫º K·∫æT QU·∫¢ ---
        result_frame = segmentor.draw_overlay(frame, mask)

        # T√≠nh to√°n v√† hi·ªÉn th·ªã FPS
        fps = 1 / (current_time - prev_time) if prev_time > 0 else 0
        prev_time = current_time
        
        # V·∫Ω th√¥ng s·ªë l√™n m√†n h√¨nh
        cv2.putText(result_frame, f"FPS: {int(fps)}", (20, 40), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
        cv2.putText(result_frame, f"Device: RTX 3050 (FP16)", (20, 80), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)

        cv2.imshow('Real-time Iris Segmentation', result_frame)

        # Nh·∫•n Q ƒë·ªÉ tho√°t
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    print("üëã Ch∆∞∆°ng tr√¨nh k·∫øt th√∫c.")

if __name__ == "__main__":
    main()